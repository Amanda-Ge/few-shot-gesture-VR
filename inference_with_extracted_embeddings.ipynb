{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Working with pre-extracted embeddings\n",
    "\n",
    "When you're testing a Few-Shot Learning models, you are going to solve hundreds of randomly sampled few-shot tasks. In doing so, you are more than likely to process the same images several times. This means that these images will go through your backbone several times, which is a waste in time and energy. Indeed, most Few-Shot Learning methods nowadays make use of a **frozen backbone**: the logic of these methods is at the feature level. Therefore, you can extract the features of your images once and for all, and then use these features to solve your few-shot tasks.\n",
    "\n",
    "All the necessary tools to do so are available in EasyFSL. In this tutorial, we will show you how to use them.\n",
    "\n",
    "## Extracting the features\n",
    "\n",
    "EasyFSL has a `predict_embeddings()` method, which takes as input a DataLoader and a torch Module, and outputs a DataFrame with all your embeddings. Let's use it to extract all the embeddings from the test set of the CUB dataset. For a backbone, we are going to use the Swin Transformer pre-trained on ImageNet and directly available from torchvision. Note that we can do that because there is no intersection between CUB and ImageNet, so we are not technically cheating. Still, the resulting performance cannot be compared with that of a model trained on CUB's train set, since the training data is not the same.\n",
    "\n",
    "First do some necessary configuration (this is not the interesting part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\tools\\Anaconda\\envs\\py39\\lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\iib\\project\\github\\fsl_gesture\n",
      "WARNING:tensorflow:From D:\\tools\\Anaconda\\envs\\py39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import random\n",
    "from statistics import mean\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from notebooks.get_dataset import *\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from easyfsl.modules import resnet12\n",
    "from easyfsl.methods import PrototypicalNetworks\n",
    "from easyfsl.samplers import TaskSampler\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import SGD, Optimizer\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from easyfsl.utils import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, gesture_data, labels):\n",
    "        self.data = gesture_data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        gesture_sample = torch.tensor(self.data[idx],dtype=torch.float)\n",
    "        label = torch.tensor(self.labels[idx].astype(np.int64))\n",
    "        \n",
    "        return (gesture_sample, label)\n",
    "    def get_labels(self):\n",
    "        return self.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we prepare the data and the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 0\n",
    "p_ids = [2,5,6,7,8,9,10,11,23,24]\n",
    "test_path = 'D:/iib_project/data/Gesture_Dataset/gestures/data/test/'\n",
    "annotation_path = 'D:/iib_project/data/Gesture_Dataset/gestures/annotations/'\n",
    "testpart1_path = 'test 1-'\n",
    "testpart2_path = 'test 2-'\n",
    "testpart3_path = 'test 3-'\n",
    "\n",
    "multiframe_gestures_test = {'Grab things':testpart2_path, 'Nozzle rotation':testpart1_path,\n",
    "                            \"Teleport\":testpart3_path, \"Two hands flick\":testpart3_path,\n",
    "                           'Null': testpart1_path}\n",
    "\n",
    "\n",
    "test, test_label = get_data_multiframes(test_path,multiframe_gestures_test, p_ids,n_test)\n",
    "test_dataset = GestureDataset(test, test_label)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "model = torchvision.models.swin_v2_t(\n",
    "    weights=torchvision.models.Swin_V2_T_Weights.IMAGENET1K_V1,\n",
    ")\n",
    "# Remove the classification head: we want embeddings, not ImageNet predictions\n",
    "model.head = nn.Flatten()\n",
    "\n",
    "# If you have a GPU, use it!\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And now we extract the embeddings. This gives us a DataFrame with the embeddings of all the images in the test set, along with their respective class_names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting embeddings: 100%|██████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.10batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            embedding  class_name\n",
      "0   [tensor(-0.1855), tensor(-0.0161), tensor(-0.1...           4\n",
      "1   [tensor(0.2868), tensor(-0.3351), tensor(-0.01...           4\n",
      "2   [tensor(-0.1425), tensor(0.0792), tensor(-0.38...           4\n",
      "3   [tensor(-0.3981), tensor(-0.4016), tensor(-0.1...           4\n",
      "4   [tensor(-0.7728), tensor(-0.6934), tensor(0.15...           4\n",
      "5   [tensor(0.3577), tensor(0.1011), tensor(-0.169...           4\n",
      "6   [tensor(-0.1443), tensor(0.0808), tensor(-0.29...           4\n",
      "7   [tensor(0.0193), tensor(-0.8467), tensor(-0.24...           4\n",
      "8   [tensor(0.0058), tensor(-0.0739), tensor(-0.09...           4\n",
      "9   [tensor(-0.2402), tensor(-0.4507), tensor(-0.0...           4\n",
      "10  [tensor(0.0966), tensor(-0.0187), tensor(-0.44...           5\n",
      "11  [tensor(-0.2819), tensor(-0.6512), tensor(-0.2...           5\n",
      "12  [tensor(0.1954), tensor(-0.1632), tensor(-0.00...           5\n",
      "13  [tensor(-0.0334), tensor(-0.4077), tensor(-0.6...           5\n",
      "14  [tensor(-0.0427), tensor(-0.1832), tensor(-0.3...           5\n",
      "15  [tensor(0.3080), tensor(-0.2878), tensor(-0.43...           5\n",
      "16  [tensor(-0.0724), tensor(-0.1516), tensor(-0.4...           5\n",
      "17  [tensor(-0.1535), tensor(-0.1617), tensor(-0.4...           5\n",
      "18  [tensor(0.1762), tensor(-0.2852), tensor(-0.54...           5\n",
      "19  [tensor(0.0787), tensor(-0.0117), tensor(0.072...           5\n",
      "20  [tensor(-0.3755), tensor(-0.7298), tensor(0.13...           6\n",
      "21  [tensor(0.0966), tensor(-0.2554), tensor(-0.13...           6\n",
      "22  [tensor(0.0138), tensor(-0.2757), tensor(-0.12...           6\n",
      "23  [tensor(0.3187), tensor(-0.3544), tensor(-0.17...           6\n",
      "24  [tensor(0.2784), tensor(-0.2339), tensor(-0.24...           6\n",
      "25  [tensor(0.0349), tensor(-0.2096), tensor(-0.36...           6\n",
      "26  [tensor(0.1383), tensor(-0.0104), tensor(-0.04...           6\n",
      "27  [tensor(-0.4241), tensor(-0.7391), tensor(-0.0...           6\n",
      "28  [tensor(0.1663), tensor(-0.1144), tensor(-0.11...           6\n",
      "29  [tensor(-0.2952), tensor(-0.4434), tensor(0.02...           6\n",
      "30  [tensor(0.0510), tensor(0.3151), tensor(-0.130...          13\n",
      "31  [tensor(0.2116), tensor(-0.0609), tensor(-0.49...          13\n",
      "32  [tensor(0.0129), tensor(-0.2797), tensor(0.014...          13\n",
      "33  [tensor(0.4278), tensor(0.5000), tensor(-0.146...          13\n",
      "34  [tensor(0.1772), tensor(-0.0901), tensor(0.053...          13\n",
      "35  [tensor(0.1724), tensor(0.3259), tensor(-0.222...          13\n",
      "36  [tensor(0.3076), tensor(-0.1402), tensor(-0.42...          13\n",
      "37  [tensor(0.2118), tensor(0.3327), tensor(-0.347...          13\n",
      "38  [tensor(0.0594), tensor(0.0175), tensor(0.0186...          13\n",
      "39  [tensor(-0.0706), tensor(0.1084), tensor(-0.22...          13\n",
      "40  [tensor(0.1480), tensor(-0.1709), tensor(-0.23...          15\n",
      "41  [tensor(-0.4682), tensor(-0.2305), tensor(-0.0...          15\n",
      "42  [tensor(-0.1957), tensor(-0.4276), tensor(0.08...          15\n",
      "43  [tensor(-0.4568), tensor(-0.4639), tensor(-0.3...          15\n",
      "44  [tensor(-0.1190), tensor(0.2883), tensor(-0.29...          15\n",
      "45  [tensor(-0.1724), tensor(0.0391), tensor(-1.13...          15\n",
      "46  [tensor(0.0561), tensor(-0.2636), tensor(-0.21...          15\n",
      "47  [tensor(0.2130), tensor(0.1576), tensor(0.0102...          15\n",
      "48  [tensor(-0.2634), tensor(-0.2297), tensor(-0.2...          15\n",
      "49  [tensor(0.1508), tensor(-0.1201), tensor(-0.34...          15\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.utils import predict_embeddings\n",
    "\n",
    "embeddings_df = predict_embeddings(dataloader, model, device=device)\n",
    "\n",
    "print(embeddings_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now have our embeddings ready to use! We will not use the backbone anymore.\n",
    "\n",
    "## Performing inference on pre-extracted embeddings\n",
    "\n",
    "To deliver the embeddings to our Few-Shot Classifier, we will need an appropriate DataLoader. We will use the `FeaturesDataset` class from EasyFSL. Since we have a DataFrame ready to use, we will use the handy `from_dataset()` initializer from `FeaturesDataset`, but you can also use `from_dict()` to initialize from a dictionary, or the built-in constructor to initialize it directly from labels and embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1.8549e-01, -1.6074e-02, -1.4300e-01,  3.3690e-01,  1.8613e-01,\n",
      "        -8.8492e-02, -8.1999e-02,  7.1264e-02,  2.1094e-01,  1.2463e-01,\n",
      "         1.5670e-01, -1.6324e-01,  4.5528e-02,  5.7922e-02, -3.6548e-02,\n",
      "         8.5379e-02,  1.7829e-01, -1.8733e-02,  2.4848e-01, -7.7767e-02,\n",
      "         4.4384e-02, -4.3345e-02,  8.5886e-02,  5.2851e-02,  7.6360e-02,\n",
      "         1.6578e-01,  2.2752e-01, -8.3451e-03,  2.9112e-02, -7.2518e-02,\n",
      "        -1.0330e-01,  7.9279e-02, -3.7797e-02,  7.6986e-02,  2.9532e-02,\n",
      "         1.0439e-01,  5.2560e-03, -1.8880e-01,  1.2565e-01,  1.4312e-01,\n",
      "        -4.9465e-02, -1.9007e-01,  3.3652e-01, -2.0023e-03,  8.1917e-02,\n",
      "        -1.3372e-01, -4.0351e-02, -9.3523e-02, -1.2170e-01, -5.0943e-02,\n",
      "        -1.0378e-01, -1.5065e-01, -1.0306e-01,  1.8717e-01, -7.0349e-02,\n",
      "         1.7137e-01, -4.0008e-01, -2.2976e-01,  2.2477e-02, -7.3796e-03,\n",
      "        -3.7446e-02,  9.1540e-02,  4.4683e-02,  1.8917e-01,  2.4368e-01,\n",
      "        -9.5658e-02,  2.1460e-01,  2.0822e-01,  7.3722e-02,  2.6287e-01,\n",
      "         1.4459e-01,  1.4671e-01,  1.6034e-01,  1.7241e-01,  5.5654e-02,\n",
      "         1.4207e-01,  1.6808e-01, -3.7207e-02,  4.7546e-04,  4.2547e-03,\n",
      "         4.5201e-03, -6.0218e-02,  1.6720e-01,  2.1089e-01,  1.7066e-01,\n",
      "        -4.5859e-02, -2.0164e-01, -1.1749e-01,  1.9433e-02, -6.3296e-02,\n",
      "        -1.0975e-02,  7.2543e-02,  4.4256e-02,  4.4076e-01, -2.9155e-02,\n",
      "         2.6307e-01,  1.6052e-01,  1.5238e-01, -4.1294e-02,  2.3726e-01,\n",
      "        -1.2972e-01,  1.6273e-02, -6.3389e-02, -2.2491e-01, -1.2240e-01,\n",
      "        -1.2962e-02, -3.0163e-01, -7.4008e-03, -2.7186e-01, -1.9669e-01,\n",
      "         2.0044e-02,  1.8129e-03,  2.8966e-01,  1.4950e-01, -1.4716e-01,\n",
      "        -3.5016e-02,  3.0736e-01,  2.4196e-02,  1.6975e-01,  8.4938e-03,\n",
      "         5.9097e-02,  1.7273e-01,  1.6502e-01, -1.8281e-01,  2.9332e-02,\n",
      "         2.5749e-01,  3.1111e-02, -9.0240e-02, -4.5786e-02, -1.8329e-02,\n",
      "         1.5097e-01,  6.5670e-02, -2.2290e-01,  6.2695e-02,  8.8358e-02,\n",
      "         4.0551e-02, -4.1260e-02,  1.4534e-01,  1.9297e-01,  6.4433e-02,\n",
      "        -1.7257e-01,  8.2443e-02, -4.0913e-03, -6.8546e-02, -7.1946e-02,\n",
      "        -1.0120e-03, -1.5372e-01, -5.6765e-02,  6.5769e-02,  1.7901e-01,\n",
      "         1.0190e-01,  1.1329e-01, -3.2401e-02, -9.7311e-03, -2.8468e-02,\n",
      "         1.8509e-01, -1.5859e-01, -2.6459e-01,  1.1288e-01, -3.3230e-01,\n",
      "         7.9997e-02,  2.3724e-02,  1.5450e-01,  1.3338e-01,  1.2012e-01,\n",
      "         3.9753e-02,  1.8360e-01,  6.5531e-02, -6.8643e-02, -5.8991e-03,\n",
      "        -6.8249e-02,  6.1539e-02, -1.1412e-01,  2.1940e-01, -1.3366e-01,\n",
      "        -2.1595e-01,  2.8383e-02, -5.7099e-02,  1.6028e-01, -2.9386e-01,\n",
      "         1.8336e-01,  2.4461e-02, -6.5528e-02,  5.7885e-02,  5.1087e-02,\n",
      "         1.9293e-01, -9.9414e-02, -2.1542e-01,  2.1085e-01,  1.2284e-01,\n",
      "        -1.5506e-02,  1.6165e-01,  8.2968e-02,  9.9472e-02, -1.8718e-01,\n",
      "         3.4260e-01, -1.7564e-01,  3.3567e-01,  9.2639e-03,  1.2801e-02,\n",
      "         2.0506e-01, -1.2639e-01,  1.1636e-01, -6.6864e-02, -2.8559e-02,\n",
      "        -3.0771e-02,  8.6320e-02, -1.4928e-02,  6.8073e-03,  9.7107e-04,\n",
      "         4.3730e-02,  1.9817e-01,  3.0474e-02,  3.1178e-04,  1.3711e-01,\n",
      "        -1.7672e-01,  3.0859e-02, -7.2411e-04,  1.6075e-01, -1.9201e-01,\n",
      "         1.9292e-01,  2.2597e-02,  3.8600e-02,  7.6790e-02,  8.0925e-02,\n",
      "        -1.1495e-01,  2.0330e-01, -7.8289e-02,  6.0109e-02,  1.1990e-02,\n",
      "         6.9445e-02, -4.2445e-02,  1.9126e-01,  1.9284e-01,  3.0722e-01,\n",
      "         1.7800e-01,  5.6814e-02,  9.6704e-02, -1.2054e-01, -2.0178e-01,\n",
      "        -1.8108e-01,  1.5608e-02,  5.3729e-02,  1.2429e-01, -1.6909e-01,\n",
      "         1.0588e-01, -1.8030e-02, -1.2221e-03, -3.8289e-01, -1.0129e-01,\n",
      "        -7.9636e-02, -5.6354e-02,  1.1418e-01, -1.5505e-01,  3.7339e-01,\n",
      "         1.5743e-01,  1.4512e-01,  1.1996e-01, -9.8009e-03,  3.2541e-01,\n",
      "         3.7621e-02,  1.4101e-01,  4.7756e-02, -1.9123e-01, -1.1231e-01,\n",
      "         1.7409e-01,  1.1392e-01,  8.0842e-02,  9.2756e-02, -4.9687e-02,\n",
      "        -1.3078e-01,  1.1931e-01, -4.1310e-02,  7.9067e-02, -1.7630e-01,\n",
      "        -4.6838e-02,  2.2698e-01,  8.7438e-02,  1.9110e-01, -7.4931e-02,\n",
      "         9.2368e-02, -1.3816e-01,  4.6340e-02, -6.1200e-03,  2.4593e-01,\n",
      "         1.6983e-01, -4.3430e-02,  8.8310e-03,  4.0502e-01,  1.2793e-01,\n",
      "        -2.7349e-01,  1.3414e-01, -3.6527e-02, -1.3440e-01, -5.1598e-04,\n",
      "         1.2099e-01, -2.1591e-02,  8.1121e-02,  2.9427e-02,  6.6873e-02,\n",
      "        -1.5398e-01,  1.8339e-02,  2.9349e-02, -6.2707e-02,  1.6803e-01,\n",
      "         2.3136e-02, -3.7357e-02,  2.2900e-02,  1.2466e-01,  2.0936e-01,\n",
      "         3.3620e-02,  2.2228e-01, -2.0865e-01,  2.6492e-01, -5.0141e-04,\n",
      "         5.7216e-02,  4.6564e-01,  6.8844e-02,  1.7408e-02, -8.1928e-02,\n",
      "         1.6479e-01, -1.5527e-02,  2.1280e-01,  6.5371e-03,  8.5103e-02,\n",
      "        -3.8132e-02, -2.0896e-01, -6.6569e-02,  1.3857e-01, -8.2148e-02,\n",
      "         2.6395e-01, -8.8065e-03, -7.3818e-02,  8.5094e-02,  8.1866e-02,\n",
      "        -1.3306e-01, -7.7609e-02,  2.5066e-01, -2.5352e-01,  2.7644e-01,\n",
      "        -2.9015e-01, -5.8562e-02,  4.3277e-02, -1.4619e-01, -2.1063e-02,\n",
      "        -1.5093e-01,  4.6887e-02,  1.0584e-01,  1.9269e-01,  7.4603e-02,\n",
      "         3.7328e-01,  3.4717e-02,  3.4116e-02,  1.9274e-01,  2.6913e-01,\n",
      "         1.4301e-01, -4.1211e-02, -6.2482e-02,  1.2481e-01,  1.6583e-01,\n",
      "         5.1743e-02, -2.1792e-01, -1.4029e-01,  1.5397e-01, -7.1254e-02,\n",
      "        -5.0033e-02,  2.2770e-01,  6.4053e-02, -2.4717e-01,  2.8810e-02,\n",
      "         1.4303e-01,  8.7348e-02,  1.2104e-01, -4.8116e-02, -1.8931e-01,\n",
      "        -9.3170e-02,  9.1203e-02,  1.1264e-01,  1.1130e-01,  2.3089e-01,\n",
      "        -1.8529e-01,  1.4332e-01,  2.9926e-01, -3.0982e-01, -8.6795e-02,\n",
      "         1.7715e-01, -3.7095e-01, -1.8334e-01, -2.3018e-02,  3.9010e-01,\n",
      "         1.1121e-01,  7.6278e-02,  8.7374e-02,  3.0649e-01,  1.2124e-01,\n",
      "        -4.3779e-02,  1.5496e-01, -1.9915e-01,  5.3610e-02, -5.9198e-02,\n",
      "         2.5959e-01, -1.5561e-01, -9.9402e-02,  8.9885e-02,  9.6585e-02,\n",
      "         8.0927e-02,  4.7955e-02,  2.1488e-01, -6.8407e-02,  1.4023e-02,\n",
      "         6.7770e-02,  1.4425e-01, -9.3653e-02, -1.1435e-01,  1.7232e-01,\n",
      "         1.4268e-01, -6.0925e-02,  2.0298e-01,  2.3623e-01,  6.1885e-02,\n",
      "         1.6626e-01, -7.1372e-02,  3.7521e-02,  1.1448e-02,  2.1916e-02,\n",
      "         1.3524e-02, -1.1118e-01,  1.6998e-01,  2.4643e-01,  1.1478e-01,\n",
      "         4.9622e-02, -5.5946e-02,  1.5226e-01,  1.0356e-01,  9.0191e-02,\n",
      "        -1.3315e-01, -5.6621e-02,  7.2307e-02,  6.8995e-02,  9.4424e-02,\n",
      "        -7.8949e-02,  1.0401e-01,  3.5581e-01, -1.0070e-01,  6.7898e-03,\n",
      "        -1.2740e-03,  1.1358e-01,  8.1762e-02, -2.7365e-01,  5.8613e-01,\n",
      "         3.9794e-01,  1.1192e-01,  2.6647e-01, -1.5949e-01,  6.4707e-03,\n",
      "        -1.5112e-01,  7.3910e-03, -2.6118e-01,  1.2764e-02, -2.1241e-02,\n",
      "         3.4043e-02,  1.7259e-02,  2.9076e-02, -1.7044e-02,  2.1196e-01,\n",
      "         4.1074e-02,  1.1208e-01, -3.9249e-03, -1.5073e-02,  2.2624e-01,\n",
      "         1.3616e-01, -6.8198e-03, -4.2255e-02,  1.9252e-01, -3.4630e-02,\n",
      "         8.2163e-02, -1.6457e-01,  6.1551e-02,  1.0209e-01,  3.6585e-01,\n",
      "         9.3498e-02,  1.3288e-01, -1.1817e-01, -1.7210e-02,  8.1459e-02,\n",
      "        -8.3007e-02,  1.4861e-01,  1.8432e-01,  2.6242e-01, -1.2867e-01,\n",
      "         1.5153e-01,  1.3741e-01,  1.6270e-01, -2.0627e-01,  7.4677e-02,\n",
      "         1.8829e-01, -1.8737e-01,  4.4138e-02,  2.7951e-02,  8.1951e-02,\n",
      "         7.9255e-02,  2.0284e-01,  1.3955e-01,  2.0484e-01, -1.1344e-01,\n",
      "        -1.1226e-01,  1.1619e-01,  5.9575e-02, -2.6449e-01,  2.6871e-01,\n",
      "        -1.6752e-03,  4.1918e-02,  7.1074e-02,  4.3344e-02,  7.7265e-02,\n",
      "         2.1462e-02, -3.0668e-01, -5.5562e-02,  2.8872e-02, -1.9400e-01,\n",
      "        -1.9578e-01,  1.5602e-01,  2.0392e-01, -3.1134e-01,  9.6368e-02,\n",
      "        -2.9181e-02, -1.6504e-01, -4.3298e-02, -1.9525e-02,  3.2809e-02,\n",
      "         4.0370e-02,  7.8052e-02, -1.0094e-01, -1.5275e-01, -5.8120e-02,\n",
      "         1.5245e-01,  1.8380e-01, -1.5727e-01,  1.0315e-01,  7.4662e-02,\n",
      "        -2.3287e-01,  2.1308e-01, -7.8647e-02,  1.8719e-01,  3.6081e-01,\n",
      "         1.3510e-01,  2.9992e-01,  1.1676e-02, -5.1113e-02, -8.9265e-02,\n",
      "         5.8189e-02,  3.2684e-02, -3.6605e-02, -1.2776e-02,  1.3062e-01,\n",
      "         8.1248e-03,  5.5653e-02, -7.7721e-02, -1.4382e-01,  6.6541e-02,\n",
      "         1.9864e-01,  1.6749e-02, -7.3184e-03,  6.5782e-02,  3.8664e-02,\n",
      "         1.9377e-01, -1.3442e-01,  6.6242e-02,  1.9580e-01,  2.2440e-01,\n",
      "        -3.0118e-01, -4.8752e-02, -8.3530e-02, -1.2795e-01,  2.0546e-01,\n",
      "        -4.0702e-02,  1.4447e-01, -1.1870e-01, -3.2784e-02, -2.1283e-02,\n",
      "        -1.4266e-01,  9.8192e-02,  3.6075e-02, -1.8980e-02,  1.7480e-01,\n",
      "        -1.4209e-02, -1.1497e-01, -1.3208e-01,  5.7688e-02,  2.3386e-01,\n",
      "         1.3680e-02,  1.5066e-01, -1.4984e-01,  9.7149e-02,  5.6814e-02,\n",
      "        -8.3929e-02, -9.6445e-02,  1.0464e-01, -2.6747e-02, -1.9854e-02,\n",
      "         1.7155e-01,  2.9799e-02,  1.9243e-01,  1.5708e-01,  5.9901e-02,\n",
      "         1.9453e-01,  7.3429e-02, -4.7307e-02, -1.9760e-02,  3.3222e-02,\n",
      "         9.2340e-02, -1.1561e-01, -1.8966e-02,  1.0088e-01, -1.3810e-02,\n",
      "         6.4696e-02, -1.8937e-01,  7.8082e-02,  1.0672e-01, -7.8913e-02,\n",
      "         1.1660e-01, -2.8656e-01,  3.1535e-01,  7.2036e-02, -5.6000e-02,\n",
      "         1.4691e-02,  9.9659e-02, -3.0628e-02,  3.0006e-02,  2.4552e-01,\n",
      "         1.5879e-01,  1.8008e-01, -3.9434e-02,  2.4251e-01,  4.2709e-01,\n",
      "         6.0852e-02,  9.2369e-02,  1.4188e-01,  1.1071e-02, -9.4461e-02,\n",
      "         1.5058e-01, -6.1676e-02,  5.7606e-02,  2.8927e-01, -6.5952e-02,\n",
      "         1.9022e-01,  1.8886e-01, -8.4943e-02,  3.1687e-02,  1.8089e-01,\n",
      "         9.7677e-03,  1.3298e-01,  8.1843e-02,  1.3277e-02,  2.1696e-02,\n",
      "         1.1797e-02,  4.7666e-03, -1.7519e-01, -5.0147e-02, -1.5971e-03,\n",
      "         3.4431e-02,  1.8634e-01, -7.0178e-02, -1.2394e-01,  8.5795e-02,\n",
      "         3.2649e-02,  3.3252e-02,  3.1403e-01, -1.1134e-01,  1.1947e-01,\n",
      "         1.3316e-01, -6.8056e-02, -8.3736e-02,  5.5244e-01,  8.8473e-02,\n",
      "        -5.0450e-03,  3.7402e-02,  8.0432e-02,  1.3912e-01,  2.6583e-02,\n",
      "        -4.7979e-02,  1.1611e-01,  3.5672e-01, -4.0105e-02, -1.9562e-01,\n",
      "        -1.2477e-01,  1.1964e-01,  1.1177e-01,  2.7582e-01,  1.5951e-01,\n",
      "        -2.0063e-02,  1.3777e-02, -7.5909e-02, -2.8852e-02,  4.4886e-02,\n",
      "         3.9613e-01, -8.5398e-02, -1.1351e-01,  4.5797e-02,  1.4277e-01,\n",
      "        -1.2770e-01, -4.0564e-02,  3.1496e-02, -1.3168e-01,  1.2564e-01,\n",
      "        -2.0730e-02,  1.8827e-02, -5.9488e-02, -2.2778e-02,  9.7732e-02,\n",
      "         4.5545e-02,  7.5244e-02, -7.5888e-02,  3.6859e-02, -5.3405e-03,\n",
      "         2.6449e-02, -1.5221e-02, -1.1297e-01, -1.5233e-01, -6.8951e-02,\n",
      "         2.1739e-01,  1.0873e-02,  2.6439e-02, -8.9585e-02, -1.4560e-01,\n",
      "         2.4819e-01, -4.4617e-02,  4.1498e-02,  5.0992e-01,  1.3169e-01,\n",
      "         8.0459e-03,  1.1501e-01, -6.6299e-03,  2.0182e-01, -5.2290e-02,\n",
      "         6.5034e-02,  1.9030e-01,  1.9503e-01,  5.8916e-01, -1.7283e-03,\n",
      "         2.1587e-02, -2.4806e-01,  3.6445e-01, -9.3016e-02,  2.6437e-01,\n",
      "         8.8026e-02,  1.8709e-01, -7.8604e-02, -2.9600e-03,  7.5746e-02,\n",
      "         1.5462e-01,  1.2787e-02,  3.7199e-02, -1.2852e-01,  6.6142e-02,\n",
      "        -9.2213e-02,  8.8824e-02,  4.0686e-02,  3.9814e-02,  1.4740e-03,\n",
      "        -2.5715e-01,  6.8127e-03, -2.9383e-02, -2.8878e-02,  8.9146e-02,\n",
      "         2.4165e-01, -5.0844e-02,  3.6247e-02]), 0)\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.datasets import FeaturesDataset\n",
    "\n",
    "features_dataset = FeaturesDataset.from_dataframe(embeddings_df)\n",
    "\n",
    "print(features_dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, like in all other few-shot tutorials, we are going to build a DataLoader that loads batches in the shape of few-shot tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.samplers import TaskSampler\n",
    "\n",
    "task_sampler = TaskSampler(\n",
    "    features_dataset,\n",
    "    n_way=5,\n",
    "    n_shot=1,\n",
    "    n_query=9,\n",
    "    n_tasks=100,\n",
    ")\n",
    "features_loader = DataLoader(\n",
    "    features_dataset,\n",
    "    batch_sampler=task_sampler,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    collate_fn=task_sampler.episodic_collate_fn,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We now need to instantiate our Few-Shot Classifier. We will use a Prototypical Network for simplicity, but you can use any other model from EasyFSL.\n",
    "\n",
    "Since we are working directly on features, **we don't need to initialize Prototypical Networks with a backbone**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from easyfsl.methods import PrototypicalNetworks\n",
    "\n",
    "# Default backbone if we don't specify anything is Identity.\n",
    "# But we specify it anyway for clarity and robustness.\n",
    "few_shot_classifier = PrototypicalNetworks(backbone=nn.Identity())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can now evaluate our model on the test set, and just enjoy how fast it goes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 109.41it/s, accuracy=0.323]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy : 32.31 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from easyfsl.utils import evaluate\n",
    "\n",
    "accuracy = evaluate(\n",
    "    few_shot_classifier,\n",
    "    features_loader,\n",
    "    device=\"cpu\",\n",
    ")\n",
    "\n",
    "print(f\"Average accuracy : {(100 * accuracy):.2f} %\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And that is it! Notice that when you're working on pre-extracted embeddings, you can process tasks way faster (65 tasks/s on my MacBook Pro). This should always be your default settings whenever you're working with a method that uses a frozen backbone at test-time (that's most of them).\n",
    "\n",
    "## Conclusion\n",
    "Thanks for following this tutorial. If you have any issue, please [raise one](https://github.com/sicara/easy-few-shot-learning/issues), and if EasyFSL is helping you, do not hesitate to [star the repository](https://github.com/sicara/easy-few-shot-learning)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
