{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2eaf75f-ae78-437c-a56d-c6b171450b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import torch\n",
    "from data_utils import *\n",
    "import torch.nn.functional as F\n",
    "\n",
    "label_map = {\"Thumb Up\":0,\"Gun\":1,\"Nozzle rotation\":2,\"Stop\":3, \"Swipe\":4,\"Circle\":5,\n",
    "         \"Heart\":6,\"Grab things\":7,\"paper\":8,\"Rock\":9,\"Scissor\":10,\n",
    "         \"Drive car\":11, \"Teleport\":12, \"Two hands scale\":13, \"Two hands delete\":14, \"Two hands flick\":15,\"Null\":16}\n",
    "train_path = 'D:/iib_project/data/Gesture_Dataset/gestures/data/train/'\n",
    "test_path = 'D:/iib_project/data/Gesture_Dataset/gestures/data/test/'\n",
    "annotation_path = 'D:/iib_project/data/Gesture_Dataset/gestures/annotations/'\n",
    "\n",
    "def get_gesture_ids_participant(gesture_name,trainpart, participant_id, path):\n",
    "    result = []\n",
    "    for root, subdirs, files in os.walk(path):\n",
    "        for filename in files:\n",
    "            if trainpart in filename and gesture_name in filename and 'participant-'+str(participant_id)+'.csv' in filename:\n",
    "                id = filename.split('-')[3]\n",
    "                result.append(id)\n",
    "    return result\n",
    "\n",
    "def read_gesture_data(path, trainpart, gesture_name, p_id, name_attri):\n",
    "    anno = pd.read_csv(os.path.join(annotation_path + gesture_name + '.csv'))\n",
    "    id_list = get_gesture_ids_participant(gesture_name,trainpart, p_id, path)\n",
    "    df = []\n",
    "    ppath = trainpart + gesture_name +'-id-'\n",
    "    for id in id_list:\n",
    "        df_sub = pd.read_csv(os.path.join(path+ppath+ id +'-participant-'+str(p_id)+'.csv'))\n",
    "        df.append(df_sub)\n",
    "    annot_gesture = []\n",
    "    for i in range(len(df)):\n",
    "        df_sub = df[i]\n",
    "        df_sub.startTime *= 100\n",
    "        id = id_list[i]\n",
    "        if df_sub[df_sub.startTime.apply(np.floor)==anno[anno.id == int(id)].iloc[0][name_attri]].empty:\n",
    "            gesture_sub = df_sub[df_sub.startTime.apply(np.ceil)==anno[anno.id == int(id)].iloc[0][name_attri]]\n",
    "        else:\n",
    "            gesture_sub = df_sub[df_sub.startTime.apply(np.floor)==anno[anno.id == int(id)].iloc[0][name_attri]]\n",
    "        annot_gesture.append(gesture_sub)\n",
    "    return annot_gesture\n",
    "\n",
    "def read_gesture_data_continuous(path, trainpart, gesture_name, p_id):\n",
    "    anno = pd.read_csv(os.path.join(annotation_path + gesture_name + '.csv'))\n",
    "    id_list = get_gesture_ids_participant(gesture_name,trainpart, p_id,path)\n",
    "    if gesture_name=='Null':\n",
    "        print (id_list)\n",
    "    df = []\n",
    "    ppath = trainpart + gesture_name +'-id-'\n",
    "    for id in id_list:\n",
    "        df_sub = pd.read_csv(os.path.join(path+ppath+ id +'-participant-'+str(p_id)+'.csv'))\n",
    "        df.append(df_sub)\n",
    "    annot_gesture = []\n",
    "    for i in range(len(df)):\n",
    "        df_sub = df[i]\n",
    "        df_sub.startTime *= 100\n",
    "        id = id_list[i]\n",
    "        startTime = anno[anno.id == int(id)].iloc[0]['startTime']\n",
    "        endTime = anno[anno.id == int(id)].iloc[0]['endTime']\n",
    "        annot = df_sub[df_sub['startTime'].between(startTime, endTime)]\n",
    "        pos = [col for col in df_sub.columns if ('l' in col or 'r' in col) and 'pos' in col]\n",
    "        annot_gesture.append(annot[pos])\n",
    "    return annot_gesture\n",
    "\n",
    "def get_absolute_position_bimanual(raw_data):\n",
    "    pos = [col for col in raw_data[0].columns if (('l' in col)or('r' in col)) and 'pos' in col]\n",
    "    abs_pos = []\n",
    "\n",
    "    for j in range(len(raw_data)):\n",
    "        i=0\n",
    "        ps=[]\n",
    "        t = raw_data[j]\n",
    "        while i < len(pos):\n",
    "            pps=[]\n",
    "            pps.append(t[pos[i]].iloc[0])\n",
    "            pps.append(t[pos[i+1]].iloc[0])\n",
    "            pps.append(t[pos[i+2]].iloc[0])\n",
    "            ps.append(pps)\n",
    "            i+=3\n",
    "        abs_pos.append(ps)\n",
    "    return np.array(abs_pos)\n",
    "\n",
    "def get_R(i,raw_data):\n",
    "    wrist_pos = [raw_data[i].l0_quat_x.iloc[0], raw_data[i].l0_quat_y.iloc[0], raw_data[i].l0_quat_z.iloc[0], raw_data[i].l0_quat_w.iloc[0]]\n",
    "    R = np.zeros((3,3))\n",
    "    x = wrist_pos[0]\n",
    "    y = wrist_pos[1]\n",
    "    z = wrist_pos[2]\n",
    "    w = wrist_pos[3]\n",
    "    R[0][0] = 1-2*y**2-2*z**2\n",
    "    R[0][1] = 2*x*y-2*z*w\n",
    "    R[0][2] = 2*x*z+2*y*w\n",
    "    R[1][0] = 2*x*y+2*z*w\n",
    "    R[1][1] = 1-2*x**2-2*z**2\n",
    "    R[1][2] = 2*y*z-2*x*w\n",
    "    R[2][0] = 2*x*z-2*y*w\n",
    "    R[2][1] = 2*y*z+2*x*w\n",
    "    R[2][2] = 1-2*x**2-2*y**2\n",
    "    R = np.array(R)\n",
    "    return R\n",
    "\n",
    "def get_wrist_abspos(i,raw_data):\n",
    "    return [raw_data[i].l0_pos_x.iloc[0], raw_data[i].l0_pos_y.iloc[0], raw_data[i].l0_pos_z.iloc[0]]\n",
    "\n",
    "def frame_transformation(raw_data, abs_pos):\n",
    "    transformed_pos = np.zeros_like(abs_pos)\n",
    "    for j in range(len(raw_data)):\n",
    "        for i in range(len(abs_pos[0])):\n",
    "            transformed_pos[j][i] = np.matmul(inv(get_R(j,raw_data)),(abs_pos[j][i]-get_wrist_abspos(j,raw_data)))\n",
    "    return transformed_pos\n",
    "\n",
    "def multiframe_transformation(data):\n",
    "    if not data:\n",
    "        return\n",
    "    transformed_data = []\n",
    "    cols = [col for col in data[0].columns if ('l' in col) or ('r' in col) and 'pos_x' in col]\n",
    "    x = [data[0].columns.get_loc(c) for c in cols if c in data[0]]\n",
    "    for i in range(len(data)):\n",
    "        transformed_data.append(preprocess(data[i].values, xlist=x,nor_to_wrist=True, relative=True))\n",
    "    return transformed_data\n",
    "\n",
    "def get_data_singlestate(path, gesture_dict, p_ids, n_shot, length=300):\n",
    "    dataset = []\n",
    "    label = []\n",
    "    for name in gesture_dict.keys():\n",
    "        count = 0\n",
    "        for pid in p_ids:\n",
    "            if count==n_shot:\n",
    "                break\n",
    "            trainpart = gesture_dict[name]\n",
    "            data = read_gesture_data(path, trainpart, name,pid,'time')\n",
    "            abs_pos = get_absolute_position_bimanual(data)\n",
    "            transformed_data = frame_transformation(data, abs_pos)\n",
    "            for d in transformed_data:\n",
    "                tensor = torch.tensor(d.reshape(1,150))\n",
    "                pad = F.pad(input=tensor, pad=(0, 0, 0, length - 1), mode='constant', value=0)\n",
    "                dataset.append(pad)\n",
    "                count+=1\n",
    "                if count==n_shot:\n",
    "                    break\n",
    "            label.extend(label_map[name] for i in range(n_shot))\n",
    "    dataset = np.asarray(dataset)\n",
    "    label = np.asarray(label)\n",
    "    return dataset.reshape(len(dataset),300,50,3).transpose(0, 3, 1, 2), label      \n",
    "\n",
    "def get_data_multiframes(path, gesture_dict,p_ids,n_shot, length=300):\n",
    "    dataset = []\n",
    "    label = []\n",
    "    for name in gesture_dict.keys():\n",
    "        count = 0\n",
    "        for pid in p_ids:\n",
    "            if count==n_shot:\n",
    "                break\n",
    "            trainpart = gesture_dict[name]\n",
    "            data = read_gesture_data_continuous(path,trainpart, name,pid)\n",
    "            transformed_data = multiframe_transformation(data)\n",
    "            dataset_temp = []\n",
    "            for i in range(len(data)):\n",
    "                tensor = torch.tensor(np.asarray(transformed_data[i]))\n",
    "                dataset_temp.append(F.pad(input=tensor, pad=(0, 0, 0, length - tensor.shape[0]), mode='constant', value=0))\n",
    "                count+=1\n",
    "                if count==n_shot:\n",
    "                    break\n",
    "            dataset.extend(d for d in dataset_temp)\n",
    "            label.extend(label_map[name] for i in range(n_shot))\n",
    "    dataset = np.asarray(dataset)\n",
    "    label = np.asarray(label)\n",
    "    return dataset.reshape(len(dataset),300,50,3).transpose(0, 3, 1, 2), label\n",
    "\n",
    "def get_max_len(path, gesture_dict,p_ids):\n",
    "    max_len = 0\n",
    "    for pid in p_ids:\n",
    "        for name in gesture_dict.keys():\n",
    "            df = read_gesture_data_continuous(path,gesture_dict[name],name,pid)\n",
    "            for i in range(len(df)):\n",
    "                max_len = max(max_len,len(df[i]))\n",
    "    return max_len\n",
    "\n",
    "def get_dataset(path, single_frame_dict, multi_frame_dict, p_ids, n_shot):\n",
    "    s_set, s_label = get_data_singlestate(path, single_frame_dict, p_ids, n_shot)\n",
    "    m_set, m_label = get_data_multiframes(path, multi_frame_dict, p_ids, n_shot)\n",
    "    d_set = np.concatenate((s_set, m_set), axis=0)\n",
    "    d_label = np.concatenate((s_label, m_label))\n",
    "    return d_set, d_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94699f17-fde4-4dac-8329-4186bc283b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test 1-Null-id-234-participant-2.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['234']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_gesture_ids_participant('Null','test 1', 2, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587ff196-63f0-4e79-b597-0dde8c11c160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
